---
layout: post
title: "Reliable RabbitMQ: Preventing Message Loss, Duplicates, and Ordering Issues"
subtitle: "Building a Reliable Messaging System with the Outbox Pattern, Acks, and Durable Queues"
date: 2025-10-31
tags: [architecture, rabbitmq, reliability, messaging]
timezone: Europe/Madrid
background: "/img/posts/01.jpg"
---

> “Duplicate messages aren’t a bug — they’re the price of reliability.”

---

## Introduction

In distributed systems, “never lose a message” sounds simple, until you try to guarantee it.  
Networks fail, consumers crash, brokers restart, and suddenly you’re facing duplicated or lost events.

In this article, we’ll explore how to build **a reliable, idempotent, and ordered message pipeline** using **RabbitMQ**.  
We’ll go through real-world failure scenarios and the patterns that keep your system consistent, even under chaos.

---

## 1. Understanding the Message Lifecycle

A message travels across three stages:

1. **Producer → Broker** (publishing)
2. **Broker → Consumer** (delivery)
3. **Consumer → Database / Side-effect** (processing)

Each stage can fail independently. Let’s see how to protect all of them.

---

## 2. Producer Safety, The Outbox Pattern

Publishing a message outside of your main transaction is dangerous:

- The transaction could be committed, but the message never gets sent.
- Or the message is sent, but the transaction rollback.

To solve this, we use the **Outbox Pattern**:
store outgoing messages **in your database**, within the same transaction that triggers them.

```ruby
# app/services/orders/create_order.rb
class CreateOrder
  def call(order_params)
    ActiveRecord::Base.transaction do
      order = Order.create!(order_params)

      OutboxEvent.create!(
        event_type: "OrderCreated",
        payload: { id: order.id, total: order.total }
      )
    end
  end
end```

Then, a background job (dispatcher) safely publishes these events to RabbitMQ with publisher confirms:

```ruby
# app/jobs/outbox_dispatcher.rb
class OutboxDispatcher
  def call
    connection = Bunny.new.start
    channel = connection.create_channel
    exchange = channel.direct('events', durable: true)

    OutboxEvent.pending.find_each do |event|
      channel.confirm_select
      exchange.publish(event.payload.to_json,
                       routing_key: event.event_type,
                       persistent: true)

      channel.wait_for_confirms
      event.mark_as_sent!
    end
  ensure
    connection.close
  end
end```

NOTE: Another popular alternative is to use tools like https://debezium.io/ to send the messages from the outbox table to RabbitMq.
 Guarantees:

No messages are lost between your app and RabbitMQ.

Everything is transactional and recoverable.

## 3. Broker Safety, Durability and Persistence

RabbitMQ won’t magically persist everything, you need to configure it properly.

Make sure:

- The queue is durable
- The message is persistent

```ruby
channel.queue('orders', durable: true)

exchange.publish(payload.to_json, persistent: true)```

Guarantees:

- Messages survive broker restarts.
- No loss even if RabbitMQ crashes mid-flight.

## 4. Consumer Safety, Acks and Idempotency

Once RabbitMQ delivers a message, it expects an acknowledgement (ack). If the consumer crashes before sending the ack, RabbitMQ re-delivers the message.

That means:

- RabbitMQ guarantees at-least-once delivery, not exactly-once.

So you must design your consumers to be idempotent, able to process the same message multiple times without side effects.

Example: Idempotent Consumer in Ruby

```ruby
class OrderCreatedConsumer
  def call(delivery_info, properties, body)
    payload = JSON.parse(body)
    message_id = properties.message_id

    return if ProcessedMessage.exists?(message_id: message_id) # Idempotency check

    ActiveRecord::Base.transaction do
      ProcessedMessage.create!(message_id: message_id)
      OrderProcessor.new.call(payload)
    end

    channel.ack(delivery_info.delivery_tag)
  rescue => e
    channel.reject(delivery_info.delivery_tag, requeue: true)
  end
end```

NOTE: Another valid approach is to use a create_or_update operation based on a unique key in the payload.
The key idea is that processing the same message twice must produce the same result, without creating duplicates or inconsistent state.

Guarantees:

- Duplicates are harmless.


Messages should be acknowledged only after the database transaction commits successfully.
This ensures that if the consumer crashes during processing, RabbitMQ will re-deliver the message, and thanks to idempotency checks, re-processing it will not cause duplicate effects.

## 5. Message Ordering: Beyond "One Consumer per Queue"

RabbitMQ guarantees FIFO only within a single queue and a single consumer.

Let’s look at a real example:

```
Use case 1 → publishes message M1
Subscriber → runs use case 2 → publishes message M2
Subscriber2 → runs use case 3 → publishes message M3
```

Now imagine a single queue with multiple consumers:

M1, M2, and M3 are enqueued in order.

RabbitMQ distributes them round-robin across consumers.

If Consumer 1 is slower than Consumer 2, M3 may finish before M1.

The observable order of effects breaks, generating bugs.

This happens because ordering guarantees stop once messages are processed concurrently, even if RabbitMQ delivered them in order.

### How to Fix It

Option 1: One Consumer per Queue (Strict FIFO)

The simplest solution: one queue + one consumer. For the next reasons:

- RabbitMQ delivers messages in order.
- Your consumer processes sequentially.
- Each message is acked only after successful processing.

You can also limit concurrency explicitly:

```ruby
channel.prefetch(1)
```

This ensures only one unacknowledged message is in flight per consumer.

Option 2: One Queue per Routing Key (Parallel + Ordered)

If you need parallelism and ordering, create one queue per entity or workflow.

Example:
Each user’s or aggregate messages go to their own queue via routing key.

exchange (direct)
├── queue_use_case_1 → consumer_use_case_1
├── queue_use_case_2 → consumer_use_case_2
└── queue_use_case_3 → consumer_use_case_3


All messages for the same key are processed sequentially in the same queue, while messages with different keys are processed in parallel.
This can be automated using a consistent hash exchange, which routes messages deterministically by key without requiring a separate queue for each user.
It ensures that all messages with the same key go to the same queue (preserving order), while different keys are distributed across queues for parallel processing.

Another interesting point is that prefetch doesn’t fix ordering. Setting prefetch = 1 limits concurrency, but doesn’t guarantee order if:

- Message processing time varies, or multiple consumers share a queue.
- Prefetch helps reduce concurrency per consumer, but not across consumers.

Typical example:

Message A arrives, then message B.
Processing A takes 4 seconds.
Processing B takes 1 second.

Even though they arrived in order A → B, the completion order will be:

B (1s)
A (4s)

The order is broken, even with prefetch = 1.

## 6. Network Failures, The Real Enemy

<h3>Common scenarios</h3>
<table>
  <thead>
    <tr>
      <th>Scenario</th>
      <th>What happens</th>
      <th>Risk</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Consumer processes message, loses connection before ack</td>
      <td>RabbitMQ re-delivers</td>
      <td>Duplicate</td>
    </tr>
    <tr>
      <td>Consumer receives message but crashes before ack</td>
      <td>RabbitMQ re-delivers</td>
      <td>Duplicate</td>
    </tr>
    <tr>
      <td>Producer publishes but loses connection before confirm</td>
      <td>Message may or may not have arrived</td>
      <td>Retry needed</td>
    </tr>
  </tbody>
</table>


### How to survive

Some strategies:

- Publisher confirms: ensures the producer knows whether the message reached the broker.
- Manual acks on consumers: prevents marking a message as processed before it has actually been completed.
- Retries and DLQs: handle errors without losing messages.
- Idempotency: key to safely processing duplicate messages without side effects.

Guarantees:

- No lost messages even under network instability.
- Only duplicates, which are safely ignored.

## 7. Putting It All Together

<h3>Common Risks and Solutions</h3>
<table>
  <thead>
    <tr>
      <th>Risk</th>
      <th>Solution</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Lost messages on publish</td>
      <td>Outbox Pattern + Publisher Confirms</td>
    </tr>
    <tr>
      <td>Lost messages in RabbitMQ</td>
      <td>Durable Queues + Persistent Messages</td>
    </tr>
    <tr>
      <td>Lost messages on consume</td>
      <td>Manual Ack after commit</td>
    </tr>
    <tr>
      <td>Duplicates</td>
      <td>Idempotency</td>
    </tr>
    <tr>
      <td>Out-of-order processing</td>
      <td>One consumer per queue or per key</td>
    </tr>
    <tr>
      <td>Network failures</td>
      <td>Retries + DLQ + Confirm mode</td>
    </tr>
  </tbody>
</table>


## 8. The Reality of Distributed Systems

You can’t have exactly-once semantics in an unreliable network.
What you can have is at-least-once delivery with idempotent consumers,
and that’s good for real-world systems.

By combining:

- Outbox pattern
- Durable queues
- Persistent messages
- Manual acks
- Idempotency
- Proper ordering strategies

you achieve no message loss and predictable, consistent behavior, even under failure.

## Final Thoughts
Building reliable message-driven systems isn’t about eliminating failure, it’s about making failure safe.
With RabbitMQ, that means embracing duplicates, ensuring order where it matters, and designing every step to survive a crash, a retry, or a network glitch.

Reliability isn’t magic, it’s discipline.
